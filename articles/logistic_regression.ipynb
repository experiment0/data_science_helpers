{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Устанавливаем стиль визуализаций в matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **задаче классификации** нужно предсказать класс объекта на основе признаков в наборе данных.\\\n",
    "Задача сводится к предсказанию целевого признака, который является **категориальным**.\n",
    "\n",
    "Если **классов**, которые нужно предскзать, только **два**, то классификация называется **бинарной**.\n",
    "\n",
    "Когда **классов**, которые нужно предскзать, **более двух**, то классификация называется **мультиклассовой (многоклассовой)**.\n",
    "\n",
    "> Модели, которые решают задачу классификации, называются **классификаторами (classifier)**.\n",
    "\n",
    "Для начала рассмотрим бинарную классификацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основе логистической регрессии лежит **логистическая функция (logistic function)** — отсюда и название модели.\\\n",
    "Более распространённое название этой функции — **сигмόида (sigmoid)**. \\\n",
    "Записывается она следующим образом:\n",
    "$$ \\sigma(z) = \\frac{1}{1+e^{-z}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где $e$ — экспонента или [число Эйлера](https://dzen.ru/a/XKW4kcYE3AId802p). \\\n",
    "Бесконечная десятичная дробь, которую обычно принимают равной $2.718...$ \\\n",
    "Построим сигмоиду для наглядности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23187791640>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# фигура + координатная плоскость\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) \n",
    "\n",
    "# точки по осям\n",
    "z_items = np.arange(-10, 10.5, 0.5, dtype=None)\n",
    "sigma_items = 1 / (1 + np.exp(-1*z_items))\n",
    "\n",
    "# график сигмоиды\n",
    "ax.plot(z_items, sigma_items, color='blue', label='$\\sigma(z)$') \n",
    "\n",
    "# ось абсцисс  \n",
    "ax.axhline(y=0.5, color='black')\n",
    "# ось ординат\n",
    "ax.axvline(x=0, color='black')\n",
    "\n",
    "# название графика\n",
    "ax.set_title('Логистическая функция (сигмоида)')\n",
    "# название оси абсцисс\n",
    "ax.set_xlabel('z')     \n",
    "# название оси ординат\n",
    "ax.set_ylabel('$\\sigma(z)$') \n",
    "\n",
    "# метки по оси абсцисс\n",
    "ax.set_xticks(np.arange(-10, 11, 1, dtype=None))\n",
    "# метки по оси ординат\n",
    "ax.set_yticks(np.arange(0, 1.25, 0.25, dtype=None))\n",
    "    \n",
    "# легенда\n",
    "ax.legend(facecolor='white', fontsize=11) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция сигмоиды реализована в [scipy.stats.logistic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.logistic.html) и [scipy.special.expit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.expit.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У сигмоиды есть два важных свойства:\n",
    "\n",
    "- Значения сигмоиды $\\sigma(z)$ лежат в диапазоне от 0 до 1 при любых значения аргумента $z$.\n",
    "\n",
    "- Сигмоида выдаёт значения $\\sigma(z)>0.5$ при аргументе $z>0$, \\\n",
    "$\\sigma(z)<0.5$ — при $z<0$ \\\n",
    "и $\\sigma(z)=0.5$ — при $z=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А это свойства вероятности. \\\n",
    "Выходом сигмоиды является число от 0 до 1, \\\n",
    "которое можно интерпретировать как вероятность принадлежности к классу 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная идея модели логистической регрессии**: \n",
    "\n",
    "модель линейной регрессии (обозначим её выход за $z$)\n",
    "$$ z=w_{0}+\\sum_{j=1}^{m} w_{j} x_{j} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подставляется в функцию сигмоиды, чтобы получить искомые оценки вероятности \\\n",
    "(оценочные величины обозначаются с «шапкой» наверху, а истинные значения — без «шапки»):\n",
    "\n",
    "$$ \\hat{P}=\\sigma(z)=\\frac{1}{1+e^{-z}}=\\frac{1}{1+e^{-w_{0}-\\sum_{j=1}^{m} w_{j} x_{j}}}=\\frac{1}{1+e^{-\\bar{w} \\cdot \\bar{x}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее для краткости будем использовать слово \"**вероятность**\", но подразумевается именно **оценка вероятности**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вероятность $\\hat{P} > 0.5$, относим объект к классу 1, \\\n",
    "а если $\\hat{P} \\leq 0.5$, относим объект к классу 0. \n",
    "\n",
    "Данное условие записывается с помощью **индикаторной функции**:\n",
    "\n",
    "$$ \\hat{y}=I[\\hat{P}]=\\left\\{\\begin{array}{l} 1, \\hat{P}>0.5 \\\\ 0, \\hat{P} \\leq 0.5 \\end{array}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так задача классификации сводится к задаче регрессии для предсказания вероятностей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученное выражение для оценки вероятности $\\hat{P}$ называется моделью логистической регрессии:\n",
    "$$ \\hat{P}=\\frac{1}{1+e^{-w_{0}-\\sum_{j=1}^{m} w_{j} x_{j}}} $$\n",
    "$$ \\hat{y}=I[\\hat{P}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для понимания геометрической интерпретации рассмотрим частный случай.**\n",
    "\n",
    "Пусть класс объекта зависит от двух признаков.\\\n",
    "Если рассматривать уравнение линейной регрессии отдельно от сигмоиды, \\\n",
    "то геометрически построить логистическую регрессию на основе двух факторов — \\\n",
    "значит найти такие коэффициенты $w_0$, $w_1$ и $w_2$ уравнения плоскости, \\\n",
    "при которых наблюдается наилучшее разделение пространства на две части.\n",
    "$$ z = w_{0} + w_{1}x_{1} + w_{2}x_{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математически подстановка в уравнение плоскости точки, которая не принадлежит ей (находится ниже или выше), \\\n",
    "означает вычисление расстояния от этой точки до плоскости.\n",
    "\n",
    "- Если точка находится ниже плоскости, расстояние будет отрицательным ($z < 0$).\n",
    "- Если точка находится выше плоскости, расстояние будет положительным ($z > 0$).\n",
    "- Если точка находится на самой плоскости, $z = 0$.\n",
    "\n",
    "Подстановка отрицательных чисел в сигмоиду приведёт к вероятности $\\hat P < 0.5$, \\\n",
    "а постановка положительных — к вероятности $\\hat P > 0.5$,. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, ключевым моментом в предсказании логистической регрессии \\\n",
    "является расстояние от точки до разделяющей плоскости в пространстве факторов. \\\n",
    "Это расстояние в литературе часто называется **отступом (margin)**. \n",
    "\n",
    "Чем больше расстояние от точки, находящейся выше разделяющей плоскости, до самой плоскости, \\\n",
    "тем больше оценка вероятности принадлежности к классу 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае, когда есть зависимость от $m$ факторов, \\\n",
    "линейное выражение, находящееся под сигмоидой, \\\n",
    "будет обозначать **разделяющую гиперплоскость**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск параметров логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска параметров логистической регрессии используется \\\n",
    "**метод максимального правдоподобия (Maximum Likelihood Estimation — MLE)**. \n",
    "\n",
    "> **Правдоподобие** — это оценка того, насколько вероятно получить \\\n",
    "истинное значение целевой переменной $y$ при данных $x$ и параметрах $w$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель метода** — найти такие параметры $w=(w_{0}, w_{1}, w_{2}, ..., w_{m})$, \\\n",
    "в которых наблюдается максимум функции правдоподобия:\n",
    "\n",
    "$$ likelihood = \\sum_{i}^{n} (y_{i} log (\\hat{P_{i}}) + (1-y_{i}) log (1-\\hat{P_{i}})) \\rightarrow max_{w} $$\n",
    "\n",
    "[Подробнее о выводе](https://habr.com/ru/articles/485872/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где:\n",
    "- $n$ — количество наблюдений.\n",
    "- $y_{i}$ - это истинный класс (1 или 0) для $i$-ого объекта из набора данных.\n",
    "- $\\hat{P_{i}} = \\sigma(z_{i})$ — предсказанная с помощью логистической регрессии \\\n",
    "вероятность принадлежности к классу 1 для $i$-ого объекта из набора данных.\n",
    "    - $z_{i}$ — результат подстановки $i$-ого объекта из набора данных \\\n",
    "    в уравнение разделяющей плоскости $z_{i}= \\bar{w} \\cdot \\bar{x_{i}}$.\n",
    "- $log$ — логарифм (обычно используется натуральный логарифм по основанию $e - ln$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если перед функцией поставить знак минус, то задача меняется на противоположную.\\\n",
    "С поиска максимума на поиск минимума.\\\n",
    "Таким образом получим функцию потерь $L(w)$, \\\n",
    "которая носит название «**функция логистических потерь**», или **logloss**. \\\n",
    "Также часто можно встретить название **кросс-энтропия**, или **cross-entropy loss**:\n",
    "$$ L(w) = \\text { logloss } =-\\sum_{i}^{n} (y_{i} log (\\hat{P_{i}}) + (1-y_{i}) log (1-\\hat{P_{i}})) \\rightarrow min_{w} $$\n",
    "$$ \\hat{P_{i}}=\\frac{1}{1+e^{-w_{0}-\\sum_{j=1}^{m} w_{j} x_{j}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция минимизируется в рамках поиска параметров логистической регрессии.\\\n",
    "Данная задача решается численным методом (при расчетах получается, что аналитического решения не существует).\n",
    "\n",
    "Например, можно использовать градиентный спуск. \\\n",
    "Итерационная формула данного метода выглядит следующим образом:\n",
    "\n",
    "$$ \\omega^{(k+1)}=\\omega^{(k)}-\\eta \\nabla L\\left(\\omega^{(k)}\\right) $$\n",
    "\n",
    "новое значение параметров $w^{(k+1)}$ \\\n",
    "получается путём сдвига текущих $w^{(k)}$ \\\n",
    "в сторону вектора антиградиента $- \\nabla L (w^{(k)})$, \\\n",
    "умноженного на темп обучения $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формула градиентного спуска для logloss** \n",
    "$$ L(w)=-\\sum_{i}^{n}\\left(y_{i} \\log \\left(\\sigma\\left(w x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\sigma\\left(w x_{i}\\right)\\right)\\right) $$\n",
    "$$ \\nabla L(w)=-\\sum_{i}^{n} x_{i}\\left(y_{i}-\\sigma\\left(w x_{i}\\right)\\right) $$\n",
    "$$ w^{(k+1)}=w^{(k)}-\\eta \\nabla L\\left(w^{(k)}\\right)=w^{(k)}+\\eta \\sum_{i}^{n} x_{i}\\left(y_{i}-\\sigma\\left(w^{(k)} x_{i}\\right)\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы повысить шанс пройти мимо локальных минимумов функции потерь, \\\n",
    "используется не сам градиентный спуск, а его модификации: \\\n",
    "например, можно использовать стохастический градиентный спуск (SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед применением градиентного спуска необходимо масштабировать данные (нормализовать / стандартизировать).\\\n",
    "Во избежание переобучения модели в функцию потерь логистической регрессии традиционно добавляется **регуляризация**.\n",
    "\n",
    "При L1-регуляризации в функцию потерь $L(w)$ добавляется штраф из суммы модулей параметров, \\\n",
    "а сама функцию logloss умножается на коэффициент $C$:\n",
    "\n",
    "$$ L(w)=C \\cdot \\log \\operatorname{loss}+\\sum_{j=1}^{m}\\left|w_{j}\\right| \\rightarrow \\min_{w} $$\n",
    "\n",
    "А при L2-регуляризации добавляется штраф из суммы квадратов параметров:\n",
    "\n",
    "$$ L(w)=C \\cdot \\log \\operatorname{loss}+\\sum_{j=1}^{m}\\left(w_{j}\\right)^{2} \\rightarrow \\min _{w} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение коэффициента $C$ — коэффициент, обратный коэффициенту регуляризации. \\\n",
    "Чем больше $C$, тем меньше «сила» регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно разделить всё соотношение на коэффициент $C$:\n",
    "$$ \\frac{L(w)}{C}=\\log \\operatorname{loss}+\\frac{1}{C} \\sum_{j=1}^{m}\\left|w_{j}\\right| \\rightarrow \\min _{w} $$\n",
    "\n",
    "Оказывается, параметры $w$, при которых достигается минимум $L(w)$ и $\\frac{L(w)}{C}$ одни и те же, \\\n",
    "так как функции отличаются только на константу. \\\n",
    "А значит, нет разницы, минимум какой функции искать — $L(w)$ или $\\frac{L(w)}{C}$. \\\n",
    "Тогда формула будет записана в следующем виде:\n",
    "$$ L(w)=\\log \\operatorname{loss}+\\frac{1}{C} \\sum_{j=1}^{m}\\left|w_{j}\\right| \\rightarrow \\min _{w} $$\n",
    "\n",
    "А если обозначить $\\alpha=\\frac{1}{C}$, то получим ту же самую структуру L1-регуляризации, что и для логистической регрессии:\n",
    "\n",
    "$$ L(w)=\\log \\operatorname{loss}+\\alpha \\sum_{j=1}^{m}\\left|w_{j}\\right| \\rightarrow \\min _{w} $$\n",
    "\n",
    "Вывод: коэффициент $C$ — это коэффициент, обратный коэффициенту регуляризации $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация логистической регрессии в sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс логистической регрессии **LogisticRegression** находится в модуле **sklearn.linear_model**.\n",
    "\n",
    "**Основные параметры LogisticRegression**\n",
    "\n",
    "- `random_state` — число, на основе которого происходит генерация случайных чисел.\n",
    "- `penalty` — метод регуляризации. Возможные значения:\n",
    "    - `'l1'` — L1-регуляризация;\n",
    "    - `'l2'` — L2-регуляризация (используется по умолчанию);\n",
    "    - `'elasticnet'` — эластичная сетка (L1+L2);\n",
    "    - `'None'` — отсутствие регуляризации.\n",
    "- `C` — коэффициент обратный коэффициенту регуляризации, то есть равен $\\frac{1}{\\alpha}$\\\n",
    ". Чем больше `C`, тем меньше регуляризация. По умолчанию `C=1`, тогда `α=1`.\n",
    "- `solver` — численный метод оптимизации функции потерь logloss, может быть:\n",
    "    - `'sag'` — стохастический градиентный спуск (нужна стандартизация/нормализация);\n",
    "    - `'saga'` — модификация предыдущего, которая поддерживает работу с негладкими функциями \\\n",
    "    (нужна стандартизация/нормализация);\n",
    "    - `'newton-cg'` — [метод Ньютона с модификацией сопряжённых градиентов](https://docs.scipy.org/doc/scipy/tutorial/optimize.html#newton-conjugate-gradient-algorithm-method-newton-cg) \\\n",
    "    (не нужна стандартизация/нормализация);\n",
    "    - `'lbfgs'` — [метод Бройдена — Флетчера — Гольдфарба — Шанно](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%91%D1%80%D0%BE%D0%B9%D0%B4%D0%B5%D0%BD%D0%B0_%E2%80%94_%D0%A4%D0%BB%D0%B5%D1%82%D1%87%D0%B5%D1%80%D0%B0_%E2%80%94_%D0%93%D0%BE%D0%BB%D1%8C%D0%B4%D1%84%D0%B0%D1%80%D0%B1%D0%B0_%E2%80%94_%D0%A8%D0%B0%D0%BD%D0%BD%D0%BE) \\\n",
    "    (не нужна стандартизация/нормализация; используется по умолчанию, \\\n",
    "    так как из всех методов теоретически обеспечивает наилучшую сходимость);\n",
    "    - `'liblinear'` — [метод покоординатного спуска](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BF%D0%BE%D0%BA%D0%BE%D0%BE%D1%80%D0%B4%D0%B8%D0%BD%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0) \\\n",
    "    (не нужна стандартизация/нормализация).\n",
    "- `max_iter` — максимальное количество итераций, выделенных на сходимость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg   plas  pres  skin   insu  mass   pedi   age            class\n",
       "0   6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0  tested_positive\n",
       "1   1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  tested_negative\n",
       "2   8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  tested_positive\n",
       "3   1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  tested_negative\n",
       "4   0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  tested_positive"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для примера возьмем данные о диабете\n",
    "diabetes_data_full = fetch_openml(name='diabetes')\n",
    "diabetes_data = diabetes_data_full['frame']\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменим в целевом признаке значение tested_positive на 1, а tested_negative на 0\n",
    "diabetes_data['class'] = diabetes_data['class'].apply(lambda x: 1 if x == 'tested_positive' else 0)\n",
    "diabetes_data['class'] = diabetes_data['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# признаки\n",
    "X = diabetes_data.drop(['class'], axis=1)\n",
    "# целевой признак\n",
    "y = diabetes_data['class']\n",
    "\n",
    "# разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаём объект класса LogisticRegression\n",
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Обучаем модель, минимизируя logloss\n",
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод **predict_proba()** возвращает две вероятности: \\\n",
    "первая соответствует вероятности принадлежности к классу 0 (диабета нет), \\\n",
    "а вторая — вероятности принадлежности к классу 1 (диабет есть). \\\n",
    "В сумме две вероятности дают 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72859774, 0.27140226],\n",
       "       [0.81207972, 0.18792028],\n",
       "       [0.89083131, 0.10916869],\n",
       "       [0.84817084, 0.15182916],\n",
       "       [0.52205108, 0.47794892]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict_proba = logistic_regression_model.predict_proba(X_test)\n",
    "# Посмотрим на первые 5 пар значений\n",
    "y_test_predict_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод **predict()** предсказывает класс. \\\n",
    "По умолчанию метод **predict()** относит объект к классу 1, \\\n",
    "если вероятность принадлежности к классу 1 > 0.5, \\\n",
    "и к классу 0, если эта вероятность < 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict = logistic_regression_model.predict(X_test)\n",
    "# Посмотрим на первые 5 пар значений\n",
    "y_test_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       123\n",
      "           1       0.62      0.65      0.63        69\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.71      0.71      0.71       192\n",
      "weighted avg       0.73      0.73      0.73       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: [-9.27627603]\n",
      "wi: [[ 0.06148433  0.03583888 -0.01265625  0.00441884 -0.00157777  0.10115814\n",
      "   0.55342816  0.03763502]]\n"
     ]
    }
   ],
   "source": [
    "# Выводим результирующие коэффициенты\n",
    "\n",
    "# свободный член w0\n",
    "print(f'w0: {logistic_regression_model.intercept_}') \n",
    "\n",
    "# остальные параметры модели w1, w2, ..., wm\n",
    "print(f'wi: {logistic_regression_model.coef_}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
