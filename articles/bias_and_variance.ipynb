{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Смещение и разброс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Переобучением (overfitting)** называется ситуация, когда модель идеально подстроилась под обучающий набор данных\n",
    "и показывает хорошее качество метрик. \\\n",
    "Но показыват плохие результаты на тестовых или новых данных.\\\n",
    "То есть, модель идеально подстроилась под обучающий набор, но не уловила общей закономерности в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Недообученим (underfitting)** называется ситуация, когда модель показывает плохие результаты и на тренировочных и на тестовых данных.\\\n",
    "То есть, модель не уловила закономерности в данных совсем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки наличия переобучения можно посчитать метрики на тренировочной и тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Смещение (bias)** — это математическое ожидание разности между истинным ответом и ответом, выданным моделью. \\\n",
    "То есть это ожидаемая ошибка модели.\n",
    ">\n",
    "> $$ bias(\\hat{y}) = M\\left [ (y - \\hat{y}) \\right ] $$\n",
    "> \n",
    ">В зарубежной литературе математическое ожидание часто обозначается как $E$:\n",
    "> $$ bias(\\hat y) = E[(y - \\hat y)] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше смещение, тем слабее модель.\\\n",
    "То есть, имеет место быть недообучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Разброс (variance)** — это вариативность ошибки, то, насколько ошибка будет отличаться, \\\n",
    "если обучать модель на разных наборах данных. \\\n",
    "Математически это дисперсия (разброс) ответов модели.\n",
    "> $$ variance(\\hat{y}) = D\\left [ (y - \\hat{y}) \\right ] $$\n",
    ">\n",
    "> В зарубежной литературе дисперсия часто обозначается как $Var$:\n",
    "> $$ variance(\\hat y) = Var[(y - \\hat y)] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше разброс, тем больше ошибка будет колебаться на разных наборах данных. \\\n",
    "Наличие высокого разброса и есть свидетельство переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически на составляющие смещения и разброса модели можно разложить любую функцию потерь. \\\n",
    "Например, разложение квадратичной ошибки (её математическое ожидание) будет выглядеть следующим образом:\n",
    "\n",
    "$$ M\\left[(y-\\widehat{y})^{2}\\right]=\\operatorname{bias}(\\hat{y})^{2}+\\operatorname{variance}(\\hat{y})+\\sigma^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод формулы  [здесь](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%BB%D0%B5%D0%BC%D0%BC%D0%B0_%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F%E2%80%93%D0%B4%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D0%B8#%D0%92%D1%8B%D0%B2%D0%BE%D0%B4).\n",
    "\n",
    "- $\\sigma^2$ — неустранимая ошибка, вызванная случайностью.\n",
    "- $bias(\\hat y)^2$ — смещение модели (в квадрате).\n",
    "- $variance(\\hat y)$ — разброс модели."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
