{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# возьмем данные о домах в Калифорнии\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аналитическое решение, метод наименьших квадратов (МНК)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В функции `linear_model.LinearRegression()` используется аналитическое решение. \\\n",
    "Метод наименьших квадратов (МНК).\n",
    "\n",
    "$$ \\bar{w}=\\left(X^{T} X\\right)^{-1} X^{T} y=Q X^{T} y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Теорема [Гаусса-Маркова](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0), говорит о том, \\\n",
    "что, если выполнены все условия теоремы, МНК всегда находит оптимальные оценки параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращение матриц имеет кубическую сложность.\\\n",
    "При большом количестве признаков это процесс ресурсозатратный.\n",
    "\n",
    "Второй недостаток МНК — это невозможность инкрементального обучения, \\\n",
    "или обучения в режиме реального времени.\n",
    "\n",
    "Третий заключается в том, что матрица Q может не существовать.\\\n",
    "Это связано с математическими особенностями вычисления обратной матрицы.\\\n",
    "Причина этой проблемы — мультиколлинеарность факторов (сильная корреляционная связь). \\\n",
    "Из-за этого коэффициенты линейной регрессии становятся слишком большими \\\n",
    "и модель становится неустойчивой. \\\n",
    "Проблема решается с помощью регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "housing_data = data['frame']\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "# проверим, что данные числовые и нет пропусков\n",
    "housing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.31978371646123604\n"
     ]
    }
   ],
   "source": [
    "# признаки\n",
    "X = housing_data.drop(['MedHouseVal'], axis=1)\n",
    "# целевой признак\n",
    "y = housing_data['MedHouseVal']\n",
    "\n",
    "# разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# создаём объект класса LinearRegression\n",
    "linear_regression_model = linear_model.LinearRegression()\n",
    "\n",
    "# обучаем модель\n",
    "linear_regression_model.fit(X_train, y_train) \n",
    "\n",
    "# получаем предсказание\n",
    "y_pred = linear_regression_model.predict(X_test)\n",
    "\n",
    "# посчитаем метрику Mean Absolute Percentage Error (MAPE) \n",
    "# (показывает среднюю абсолютную процентную ошибку предсказанных значений в отношении фактических)\n",
    "mape_linear_regression = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print('MAPE:', mape_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В среднем модель ошибается на $\\pm 32$%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: -37.02783\n",
      "wi: [ 0.4476   0.00957 -0.12476  0.79447 -0.      -0.00344 -0.41856 -0.43341]\n"
     ]
    }
   ],
   "source": [
    "# свободный член w0\n",
    "print(f'w0: {np.round(linear_regression_model.intercept_, 5)}') \n",
    "\n",
    "# остальные параметры модели w1, w2, ..., wm\n",
    "print(f'wi: {np.round(linear_regression_model.coef_, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Численное решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для минимизации функции потерь используется метод **градиентного спуска (Gradient descent)**.\n",
    "\n",
    "Для линейной регрессии необходимо найти такие параметры $w_0$, $w_1$, $w_2$, ... $w_m$, \\\n",
    "в которых находится минимум функции потерь \\\n",
    "(Функция потерь должна быть дифференцируема во всех точках в области определения. [Список доступных функций](https://scikit-learn.ru/1-5-stochastic-gradient-descent/#mathematical-formulation)).\n",
    "\n",
    "[**Градиент**](https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82) — это вектор, \n",
    "который состоит из частных производных по параметрам функции.\n",
    "\n",
    "$$ \\nabla L(w)=\\left(\\frac{\\partial L(w)}{\\partial w_{0}}, \\frac{\\partial L(w)}{\\partial w_{1}}, \\frac{\\partial L(w)}{\\partial w_{2}}, \\ldots, \\frac{\\partial L(w)}{\\partial w_{m}}\\right), $$\n",
    "\n",
    "где — $L(w)$ функция потерь, зависящая от параметров модели, функция может быть любой (например, MSE). \\\n",
    "$\\nabla$ — символ набла — символьное сокращение градиента, читается как «градиент функции $L(w)$». "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Градиент** — это вектор, который показывает направление наискорейшего роста функции, \\\n",
    "а его длина — это само значение скорости функции в точке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если поставить перед градиентом знак минус $ - \\nabla L(w)$, то мы получим вектор **антиградиента**, \\\n",
    "который показывает в сторону наискорейшего убывания функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая точка ищется по правилу\n",
    "\n",
    "$$ w^{(k+1)} = w^{(k)} - \\eta \\nabla L(w^{(k)}), $$\n",
    "\n",
    "где $w$ — это вектор параметров модели, \\\n",
    "а индекс в круглых скобках сверху означает номер точки в пространстве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новая координата $w^{(k+1)}$ в пространстве параметров определяется как текущая координата $w^{(k)}$ \\\n",
    "минус скорость роста в текущей точке $\\nabla L(w^{(k)})$, помноженная на коэффициент «скольжения».\n",
    "\n",
    "$\\eta$ (читается как «эта») - это поправочный коэффициент, который носит название темп обучения (**learning rate**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически в точке минимума длина вектора равна 0, то есть движения не происходит. \\\n",
    "Это свойство используется в качестве критерия остановки алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из проблем градиентного спуска заключается в том, \\\n",
    "что алгоритм может «застрять» в локальном минимуме и не выйти из него.\\\n",
    "Для решения этой проблемы используются его [модификации](https://habr.com/ru/articles/413853/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим реализацию стохастического градиентного спуска для линейной регрессии \\\n",
    "из библиотеки **sklearn** — [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед применением необходимо нормализовать данные, иначе велика вероятность, что алгоритм не сойдется (не найдет минимум)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем нормализатор MinMaxScaler\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# производим стандартизацию\n",
    "mm_scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = mm_scaler.transform(X_train)\n",
    "X_test_scaled = mm_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.34322653785811025\n"
     ]
    }
   ],
   "source": [
    "# создаём объект класса линейной регрессии с SGD\n",
    "sgd_regressor_model = linear_model.SGDRegressor(random_state=42)\n",
    "\n",
    "# обучаем модель — ищем параметры по методу SGD\n",
    "sgd_regressor_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# делаем предсказание\n",
    "y_pred = sgd_regressor_model.predict(X_test_scaled)\n",
    "\n",
    "# считаем MAPE\n",
    "mape_sgd_regressor = metrics.mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print('MAPE:', mape_sgd_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023442821396874203"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разница метрики MAPE с аналитическим решением \n",
    "mape_sgd_regressor - mape_linear_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод градиентного спуска несколько хуже улавливает зависимости, чем аналитическое решение. \\\n",
    "Что ожидаемо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: [1.7095]\n",
      "wi: [ 5.83848  0.76685  0.16545  0.11691  0.13821 -0.07374 -1.77815 -1.77282]\n"
     ]
    }
   ],
   "source": [
    "# свободный член w0\n",
    "print(f'w0: {np.round(sgd_regressor_model.intercept_, 5)}') \n",
    "\n",
    "# остальные параметры модели w1, w2, ..., wm\n",
    "print(f'wi: {np.round(sgd_regressor_model.coef_, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры SGDRegressor\n",
    "\n",
    "Полный набор описан в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `loss` — функция потерь. \\\n",
    "По умолчанию используется `squared_loss` — это **MSE**. \\\n",
    "Но могут использоваться и другие. \\\n",
    "Например, `huber` определяет функцию потерь Хьюбера. \\\n",
    "Эта функция менее чувствительна к выбросам, чем **MSE**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max_iter` — максимальное количество итераций, выделенное на сходимость. \\\n",
    "Значение по умолчанию — `1000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `learning_rate` — режим управления темпом обучения. \\\n",
    "Значение по умолчанию — `invscaling`. Этот режим уменьшает темп обучения по формуле, $\\eta_t = \\frac{\\eta_0}{t^p}$.\\\n",
    "Если нужно, чтобы темп обучения не менялся на протяжении всего обучения, можно выставить на `constant`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `eta0` — начальное значение темпа обучения $\\eta_0$. \\\n",
    "Значение по умолчанию — 0.01.\\\n",
    "Если параметр `learning_rate=\"constant\"`, \\\n",
    "то значение этого параметра будет темпом обучения на протяжении всех итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `power_t` — значение мощности уменьшения $p$ в формуле  $\\eta_t = \\frac{\\eta_0}{t^p}$, \\\n",
    "где $\\eta_0$ — начальное значение темпа обучения, \\\n",
    "а $t$ — номер итерации алгоритма. \\\n",
    "Данный параметр отвечает за степень знаменателя \\\n",
    "(чем больше степень, тем быстрее уменьшается значение темпа обучения с каждой итерацией). \\\n",
    "Значение по умолчанию — `0.25`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть возможность дообучить модель на новых данных в режиме реального времени ([инкрементальное обучение](https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-incremental-learning-for-large-datasets)). \\\n",
    "Повторный вызов `fit()` уточняет уже существующие параметры модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
